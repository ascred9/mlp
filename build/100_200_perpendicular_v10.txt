numb_input 5
numb_output 1
deep 5
nepoch 0
loss_func LS
step 1e-3
topology 5 5 10 5 1 
active_funcs linear lrelu lrelu lrelu linear 
input_transforms
	normal 4 0 200 95.03 32.23
	normal 4 0 180 27.55 22.95
	normal 4 37 51 40.43 3.146
	linear 2 0 0.57
	linear 2 0 6.2832
output_transforms
	linear 2 100 200
adagrad_rate 0.99
dropout_rate 0
regulization_rate 10
viscosity_rate 0.9
layer 
[  -4.70052  -3.18295  -5.04832  0.645092   3.49842
 -8.06759  -6.00032  -3.54876   5.59592   3.16988
 0.360109  -1.06447 -0.477817  0.495724  0.513636
 0.957881  0.248324  0.516773 -0.686163  0.389112
 -2.48925  0.207149 -0.245675   1.17542  -0.13946 ]
{ -95.7535 -124.322 -5.93761 -133.435  -3.3264 }
layer 
[  8.91279  4.72068  50.6906  12.1463  14.5364  32.2176   36.392  2.03339  23.2729  21.2728
 21.7583  12.0367  67.0032  20.0468  11.4341  35.6737  57.2234   1.4222  43.4121  34.9221
 4.48298 -2.88551 -8.33712  2.58977 -5.80609  10.9544 -3.93084 0.378807  10.3874 -2.40529
 37.1221  29.7806  75.6863  27.5932  36.3497  46.1892  68.3674 -1.35008   31.639  47.5321
-8.60701 -8.98286  2.02331 -13.1522 -3.95557 -1.27324 -4.04575  1.27676   5.0734  12.2165 ]
{ -44.7726 -27.4955 -89.7851 -30.8855 -33.5658 -65.2648 -69.2156 -3.00204 -68.5398 -83.4469 }
layer 
[    2.30463    1.90582   -4.61078    15.1049   -3.24918
   15.5657    2.39063   -0.33458    11.1587   -5.62805
   4.95757   0.963941    1.31673    24.4063   0.486559
   5.83617  -0.638212   -2.14626    13.4703   -4.12704
  -12.6519   -10.0093    20.7784    39.1657    21.4212
 -0.470025   0.280413    1.05143    24.6288   -2.99497
 -0.727308   0.730516   0.581953    24.6533    1.42307
   3.24997  -0.472574   0.688749   -0.16707 -0.0523067
  -6.01317    5.95407    1.27476    26.2013    6.55798
  -2.80118    5.30724   -2.21018    42.4811   -9.60218 ]
{  4.43002  15.6064     20.1 -9.69729  1.59775 }
layer 
[ -0.0128589
  0.411406
  0.205285
  -18.5564
 0.0102966 ]
{ -79.5193 }
