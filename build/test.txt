numb_input 1
numb_output 1
deep 5
nepoch 32
loss_func GOOGLE
step 1.29727e-06
topology 1 10 10 10 1 
active_funcs linear th th th linear 
input_transforms
	normal 4 -3.1416 3.1416 0 1.814
output_transforms
	normal 4 -1 1 0 0.5
adagrad_rate 0.99
dropout_rate 0
regulization_rate 1000
viscosity_rate 0.9
layer 
[    -0.364294     -1.32454 -0.000796744   0.00037704     -1.25531 -0.000580646      1.14848 -0.000183973  0.000636024   0.00271021 ]
{     0.135862    -0.964987  -0.00192151  -0.00662092      1.08397  -0.00424132     -0.72084 -0.000104298  -0.00508395  -0.00527973 }
layer 
[    0.36321    0.28123  -0.131197  -0.561164  -0.337565  -0.148946   -1.02273 -0.0486416  -0.107955  -0.728622
  -0.10978    -1.5783  0.0876561  -0.639549   -1.18566    -2.1054   0.073781 0.00458851  -0.247517    -1.8864
-0.0571888   0.152698  -0.156536 -0.0913732  -0.273322   0.042467  -0.590787   0.325283 -0.0903553 -0.0306595
 -0.263849 -0.0748947   0.411049  -0.191171    0.16136  0.0196353   -1.14628  -0.126184  -0.292551   0.099459
   1.57935   0.887861   0.329042    -0.6633   0.756998   0.530718 -0.0481468 -0.0239609   -1.34211  -0.270254
 -0.178576   0.126581  0.0894847 -0.0532532  -0.311453  0.0796773  -0.345694   0.433933  -0.216233  -0.033505
 -0.843084   -0.24833   0.287333     1.2948  -0.532282  -0.150203  -0.403116 -0.0377807   0.540815   0.423956
 -0.101589 -0.0184657  -0.160801  0.0993085 -0.0819019  0.0426763   0.738201  -0.424658 -0.0804077 -0.0335408
 -0.107277 -0.0405427   0.330106  -0.141271  0.0968941  0.0223382    -1.0933  -0.200399  -0.182885  0.0857347
 -0.263009  -0.185174    0.26824  0.0624476   0.168136  0.0460691    0.58202  -0.647202  -0.281634  0.0491958 ]
{  0.0527949  -0.894202 0.00973258   0.392167  -0.709962   0.597473   -1.64317 0.00384946  -0.326167    0.54222 }
layer 
[    0.454777    0.617137    0.342066   -0.381376 -0.00210395   -0.224517   0.0307425   -0.525902    0.806085    0.606607
    1.21552     1.14988    -1.62944     -1.0499     1.32225    0.203936   -0.930729     0.98151    -0.39597    0.749244
  -0.216646    0.252971     0.56539   -0.118968   -0.878266   0.0669094   0.0326083  0.00797868   0.0824475  -0.0598747
  -0.526786    -0.49502    0.040587  -0.0486255  -0.0920867   0.0391796     0.81529    0.405404    -1.21927   -0.128838
    0.71513   0.0686908    0.341844   -0.477167   -0.453798   -0.244495   -0.246225    -0.10202   -0.156315    0.502581
 -0.0968442    -0.10263    0.965321   -0.624287   -0.600295   0.0912209   -0.550373    0.285588  -0.0219372     1.28971
   0.606733    0.806295    -1.93439   -0.145467     1.40213   -0.121366   -0.757815    0.564124    0.451763    0.368623
 -0.0426361    0.140015   -0.897897   0.0317438      1.1682   0.0279891   0.0419532   0.0077273  -0.0220839   0.0162399
   -0.09321   -0.261119  -0.0960273    0.593189    0.581695   -0.309892     0.12041    0.125444    -0.61557   -0.905885
   0.838129     1.11625    0.188119   -0.598917   -0.288392  -0.0358316    -0.49265     1.68516    0.596474    0.333223 ]
{   -0.652748   -0.458233     1.48328    0.055254    -2.04445   -0.190753    0.674537 -0.00367052  -0.0150227   -0.456571 }
layer 
[    0.214481
   0.136792
  -0.443859
  -0.428825
   0.343057
0.000695488
  -0.128012
    0.68077
   0.762177
   0.590458 ]
{ 0.102473 }
