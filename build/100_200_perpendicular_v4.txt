numb_input 5
numb_output 1
deep 5
nepoch 34
loss_func LS
step 9.9374e-07
topology 5 5 10 5 1 
active_funcs linear lrelu lrelu lrelu linear 
input_transforms
	normal 4 0 200 95.03 32.23
	normal 4 0 180 27.55 22.95
	normal 4 37 51 40.43 3.146
	linear 2 0 0.57
	linear 2 0 6.2832
output_transforms
	linear 2 100 200
adagrad_rate 0.99
dropout_rate 0
regulization_rate 0
viscosity_rate 0.9
layer 
[ -25.2068  3.54354 -5.23695  16.6152  -2.4765
-3.21177 -5.86734 -18.1251 -13.8403 -9.08171
 3.40399  1.39639  1.55763 -5.90031 -9.96615
 2.63254 0.529794  5.97554  6.34026   10.418
  -1.069 0.439509  1.27763  2.80232   2.4126 ]
{  -124.36 -83.2355 -58.5967 -94.8976 -258.759 }
layer 
[  128.656   91.753  85.9969   53.582  142.242  119.586 -6.86676  109.456  14.3761  219.265
 -118.67 -144.566 -62.6286 -191.926  14.1773  61.4484 -66.7107 -23.2743  7.80415 -57.8817
 57.7209  9.22077  29.8363  4.30693  106.812  125.726  14.2913  99.6948 -56.0547  124.736
 172.539  129.585  138.482   112.42  266.292  173.217  115.875   238.21  62.5988   255.62
-65.1156  34.7034  11.5453 -74.5994 -19.8967  -104.27  24.2753  -134.93   32.357 -60.3883 ]
{ -140.269 -151.262 -167.659 -177.057 -275.365 -222.546 -90.8579 -264.873 -115.616 -221.387 }
layer 
[ -33.7805 -12.9019  311.785   283.42  148.278
-17.2706 -11.8126  400.083  369.187  193.673
-22.0742 -11.1435  424.236  381.633   206.64
-11.5635  -16.497  381.488  337.457  175.335
-39.2215 -5.54634  395.936  343.108  161.283
 115.399 -31.3455  294.286  270.377  98.8926
-18.6555 -10.3944  375.428  338.001  214.774
 6.68977  -6.6837  378.462  299.643   232.42
-54.9093 -41.1416  149.786  127.454  80.5041
-30.9789 -17.8687  310.614  290.013  147.207 ]
{  19.4334 -29.2712 -545.155 -427.886 -261.465 }
layer 
[  -1.5107
-48.9104
-79.4716
-90.1262
-81.9465 ]
{ 234.709 }
