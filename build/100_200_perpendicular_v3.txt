numb_input 5
numb_output 1
deep 5
nepoch 0
loss_func LS
step 1e-06
topology 5 5 10 5 1 
active_funcs linear lrelu lrelu lrelu linear 
input_transforms
	normal 4 0 200 95.03 32.23
	normal 4 0 180 27.55 22.95
	normal 4 37 51 40.43 3.146
	linear 2 0 0.57
	linear 2 0 6.2832
output_transforms
	linear 2 100 200
adagrad_rate 0.99
dropout_rate 0
regulization_rate 0
viscosity_rate 0.9
layer 
[ -25.2091  3.54125 -5.23466  16.6129 -2.47878
 -3.2119 -5.86747  -18.125 -13.8404 -9.08186
 3.40541  1.39781  1.55621 -5.89889 -9.96473
 2.63228 0.529537   5.9758     6.34  10.4177
-1.06952 0.438993  1.27815   2.8018  2.41208 ]
{  -124.36 -83.2354 -58.5968 -94.8975 -258.759 }
layer 
[  128.653   91.756  85.9999   53.579  142.245  119.583 -6.86377  109.459  14.3731  219.262
 -118.67 -144.566 -62.6287 -191.926  14.1772  61.4485 -66.7108 -23.2744  7.80424 -57.8816
 57.7193  9.22233  29.8379  4.30538  106.814  125.724  14.2929  99.6964 -56.0563  124.734
  172.54  129.584  138.481  112.421  266.291  173.218  115.874  238.209  62.5999  255.621
-65.1154  34.7032  11.5451 -74.5992 -19.8969  -104.27  24.2751  -134.93  32.3572 -60.3881 ]
{ -140.269 -151.262 -167.659 -177.057 -275.365 -222.546  -90.858 -264.873 -115.616 -221.387 }
layer 
[   -33.78 -12.9014  311.785   283.42  148.278
-17.2706 -11.8126  400.083  369.187  193.673
-22.0743 -11.1436  424.236  381.633   206.64
-11.5617 -16.4952   381.49  337.459  175.337
-39.2216 -5.54642  395.936  343.108  161.283
 115.399 -31.3452  294.286  270.377  98.8929
-18.6564 -10.3953  375.427      338  214.773
 6.68974 -6.68373  378.462  299.643   232.42
-54.9098 -41.1421  149.786  127.454  80.5036
-30.9785 -17.8683  310.614  290.013  147.207 ]
{  19.4333 -29.2713 -545.155 -427.886 -261.465 }
layer 
[ -1.51114
-48.9104
-79.4716
-90.1262
-81.9465 ]
{ 234.709 }
